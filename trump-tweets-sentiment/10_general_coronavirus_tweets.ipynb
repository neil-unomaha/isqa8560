{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark For Tone and Sentiment Regarding Twitter Users Regarding Coronavirus\n",
    "\n",
    "Doctor Hall Provided me a collection of tweets that are coronavirus-related. The purpose is to prepare a collection of tweets with sentiment and tone scores which we can use as a bench mark to compare against Trump's tweets.\n",
    "\n",
    "**This code does the following:**\n",
    "* Grabs a random sample of 200 tweets from the collection of tweets \n",
    "  * 200 tweets because that is the same amount of tweets in each of the two sets of Trump Tweets\n",
    "* Removes all columns except for the `NewID, Text, Date` columns\n",
    "* `Curls` for the IBM Watson Tone Analyzer scores for each of the tweets and appends the result to the dataframe\n",
    "* Appends the VADER polarity scores for each of the tweets and appends the result to the dataframe\n",
    "* Pickles the dataframe\n",
    "* Create a corpus of all of the text within the tweets\n",
    "* Get the VADER polarity scores and the IBM Watson Tone Analyzer scores, and pickle the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "import nltk\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize VADER\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_tweets_df = pd.read_csv('all-data-combined.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "# limit the columns to the id, text, and date\n",
    "limit_cols_gen_tweets_df = gen_tweets_df[['NewID','Text', 'Date']]\n",
    "\n",
    "# only grab 200 tweets\n",
    "sample_of_tweets = limit_cols_gen_tweets_df.sample(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the IBM Tone Analyzer Columns and initialize to 0.0\n",
    "sample_of_tweets['analytical'] = 0.0\n",
    "sample_of_tweets['anger']      = 0.0\n",
    "sample_of_tweets['confident']  = 0.0\n",
    "sample_of_tweets['fear']       = 0.0\n",
    "sample_of_tweets['joy']        = 0.0\n",
    "sample_of_tweets['sadness']    = 0.0\n",
    "sample_of_tweets['tentative']  = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the rows, call IBM Watson Tone Analyzer and pass in the text\n",
    "# Record the results in the corresponding row's columns\n",
    "\n",
    "for i, row in sample_of_tweets.iterrows():\n",
    "    with open(\"temp_text.txt\", \"w\", encoding=\"utf8\") as outfile:\n",
    "        outfile.write(row[\"Text\"])\n",
    "\n",
    "    response = !curl -X POST -u \"apikey:MY-KEY\" --header \"Content-Type: text/plain\" --data-binary @\\Users\\netho\\Desktop\\TRUMP_TWEETS\\trump-corona-sentiment\\temp_text.txt \"MY-URL\"\n",
    "    \n",
    "    # convert to JSON\n",
    "    json_response = json.loads(response[-1])\n",
    "    \n",
    "    for tone in json_response['document_tone']['tones']:\n",
    "        if tone['tone_id'] == 'analytical':\n",
    "            sample_of_tweets.at[i,'analytical'] = tone['score']\n",
    "        elif tone['tone_id'] == 'anger':\n",
    "            sample_of_tweets.at[i,'anger'] = tone['score']\n",
    "        elif tone['tone_id'] == 'confident':\n",
    "            sample_of_tweets.at[i,'confident'] = tone['score']\n",
    "        elif tone['tone_id'] == 'fear':\n",
    "            sample_of_tweets.at[i,'fear'] = tone['score']\n",
    "        elif tone['tone_id'] == 'joy':\n",
    "            sample_of_tweets.at[i,'joy'] = tone['score']\n",
    "        elif tone['tone_id'] == 'sadness':\n",
    "            sample_of_tweets.at[i,'sadness'] = tone['score']\n",
    "        elif tone['tone_id'] == 'tentative':\n",
    "            sample_of_tweets.at[i,'tentative'] = tone['score']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle the tweets which now have the IBM Watson Tone Analyzer scores\n",
    "sample_of_tweets.to_pickle(\"general_tweets_with_tone.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and initialize the VADER polarity column within the dataframe\n",
    "sample_of_tweets['vader_polarity'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the VADER polarity scores per row\n",
    "for i, row in sample_of_tweets.iterrows():\n",
    "    sample_of_tweets.at[i,'vader_polarity'] = sid.polarity_scores(row[\"Text\"])['compound']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle the tweets which now have both the IBM Watson Tone Analyzer scores, as well as VADER polarity scores\n",
    "sample_of_tweets.to_pickle(\"general_tweets_with_tone_and_sentiment.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a corpus of tweets\n",
    "corpus_tweets =  {'text': ''}\n",
    "\n",
    "for i, row in sample_of_tweets.iterrows():\n",
    "    corpus_tweets['text'] = corpus_tweets['text'] + \" \" +  sample_of_tweets.at[i,'Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set VADER polarity score\n",
    "corpus_tweets['vader_polarity'] = sid.polarity_scores(corpus_tweets['text'])['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize IBM Watson Tone Analyzer Scores\n",
    "corpus_tweets['analytical'] = 0.0\n",
    "corpus_tweets['anger']      = 0.0\n",
    "corpus_tweets['confident']  = 0.0\n",
    "corpus_tweets['fear']       = 0.0\n",
    "corpus_tweets['joy']        = 0.0\n",
    "corpus_tweets['sadness']    = 0.0\n",
    "corpus_tweets['tentative']  = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp_text.txt\", \"w\", encoding=\"utf8\") as outfile:\n",
    "    outfile.write(corpus_tweets['text'])\n",
    "\n",
    "# Run the text through the IBM Watson Tone Analyzer\n",
    "response = !curl -X POST -u \"apikey:MY-KEY\" --header \"Content-Type: text/plain\" --data-binary @\\Users\\netho\\Desktop\\TRUMP_TWEETS\\trump-corona-sentiment\\temp_text.txt \"MY-URL\"\n",
    "tone_analyzer_response = json.loads(response[-1])\n",
    "\n",
    "# Set the tone values for each tone if present\n",
    "for tone in tone_analyzer_response['document_tone']['tones']:\n",
    "    if tone['tone_id'] == 'analytical':\n",
    "        corpus_tweets['analytical'] = tone['score']\n",
    "    elif tone['tone_id'] == 'anger':\n",
    "        corpus_tweets['anger']      = tone['score']\n",
    "    elif tone['tone_id'] == 'confident':\n",
    "        corpus_tweets['confident']  = tone['score']\n",
    "    elif tone['tone_id'] == 'fear':\n",
    "        corpus_tweets['fear']       = tone['score']\n",
    "    elif tone['tone_id'] == 'joy':\n",
    "        corpus_tweets['joy']        = tone['score']\n",
    "    elif tone['tone_id'] == 'sadness':\n",
    "        corpus_tweets['sadness']    = tone['score']\n",
    "    elif tone['tone_id'] == 'tentative':\n",
    "        corpus_tweets['tentative']  = tone['score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tweets_list = [corpus_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tweets_df = pd.DataFrame.from_dict(corpus_tweets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle the corpus which now has both the IBM Watson Tone Analyzer scores, as well as VADER polarity scores\n",
    "corpus_tweets_df.to_pickle('corpus_general_tweets_with_tone_and_sentiment.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
