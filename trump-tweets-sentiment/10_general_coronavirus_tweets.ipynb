{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark For Tone and Sentiment Regarding Twitter Users Regarding Coronavirus\n",
    "\n",
    "Doctor Hall Provided me a collection of tweets that are coronavirus-related. The purpose is to prepare a collection of tweets with sentiment and tone scores which we can use as a bench mark to compare against Trump's tweets.\n",
    "\n",
    "**This code does the following:**\n",
    "* Grabs a random sample of 200 tweets from the collection of tweets \n",
    "  * 200 tweets because that is the same amount of tweets in each of the two sets of Trump Tweets\n",
    "* Removes all columns except for the `NewID, Text, Date` columns\n",
    "* `Curls` for the IBM Watson Tone Analyzer scores for each of the tweets and appends the result to the dataframe\n",
    "* Appends the VADER polarity scores for each of the tweets and appends the result to the dataframe\n",
    "* Pickles the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "import nltk\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize VADER\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_tweets_df = pd.read_csv('all-data-combined.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "# limit the columns to the id, text, and date\n",
    "limit_cols_gen_tweets_df = gen_tweets_df[['NewID','Text', 'Date']]\n",
    "\n",
    "# only grab 200 tweets\n",
    "sample_of_tweets = limit_cols_gen_tweets_df.sample(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the IBM Tone Analyzer Columns and initialize to 0.0\n",
    "sample_of_tweets['analytical'] = 0.0\n",
    "sample_of_tweets['anger']      = 0.0\n",
    "sample_of_tweets['confident']  = 0.0\n",
    "sample_of_tweets['fear']       = 0.0\n",
    "sample_of_tweets['joy']        = 0.0\n",
    "sample_of_tweets['sadness']    = 0.0\n",
    "sample_of_tweets['tentative']  = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the rows, call IBM Watson Tone Analyzer and pass in the text\n",
    "# Record the results in the corresponding row's columns\n",
    "\n",
    "for i, row in sample_of_tweets.iterrows():\n",
    "    with open(\"temp_text.txt\", \"w\", encoding=\"utf8\") as outfile:\n",
    "        outfile.write(row[\"Text\"])\n",
    "\n",
    "    response = !curl -X POST -u \"apikey:MY-KEY\" --header \"Content-Type: text/plain\" --data-binary @\\Users\\netho\\Desktop\\TRUMP_TWEETS\\trump-corona-sentiment\\temp_text.txt \"MY-URL\"\n",
    "    \n",
    "    # convert to JSON\n",
    "    json_response = json.loads(response[-1])\n",
    "    \n",
    "    for tone in json_response['document_tone']['tones']:\n",
    "        if tone['tone_id'] == 'analytical':\n",
    "            sample_of_tweets.at[i,'analytical'] = tone['score']\n",
    "        elif tone['tone_id'] == 'anger':\n",
    "            sample_of_tweets.at[i,'anger'] = tone['score']\n",
    "        elif tone['tone_id'] == 'confident':\n",
    "            sample_of_tweets.at[i,'confident'] = tone['score']\n",
    "        elif tone['tone_id'] == 'fear':\n",
    "            sample_of_tweets.at[i,'fear'] = tone['score']\n",
    "        elif tone['tone_id'] == 'joy':\n",
    "            sample_of_tweets.at[i,'joy'] = tone['score']\n",
    "        elif tone['tone_id'] == 'sadness':\n",
    "            sample_of_tweets.at[i,'sadness'] = tone['score']\n",
    "        elif tone['tone_id'] == 'tentative':\n",
    "            sample_of_tweets.at[i,'tentative'] = tone['score']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle the tweets which now have the IBM Watson Tone Analyzer scores\n",
    "sample_of_tweets.to_pickle(\"general_tweets_with_tone.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and initialize the VADER polarity column within the dataframe\n",
    "sample_of_tweets['vader_polarity'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the VADER polarity scores per row\n",
    "for i, row in sample_of_tweets.iterrows():\n",
    "    sample_of_tweets.at[i,'vader_polarity'] = sid.polarity_scores(row[\"Text\"])['compound']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle the tweets which now have both the IBM Watson Tone Analyzer scores, as well as VADER polarity scores\n",
    "sample_of_tweets.to_pickle(\"general_tweets_with_tone_and_sentiment.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
